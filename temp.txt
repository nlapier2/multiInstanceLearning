"CAMIL": Clustering and Assembly with Multiple Instance Learning
CAMIL H-BoW and CAMIL D-BoW

Original 60: SRR413*, where * is 556-557, 646-664, 666-682, 684-702, 757-759

Size of all 218 available patients in FASTQ format: 3.7TB - (511+250+626+42) = 2.3TB
Gotten with du -sh. Average patient file size: 10.82GB
After assembly: 17.9GB total size
Cluster run time: 10 hours, 51 minutes, 29 seconds
SVM-light run time: 10 minutes, 17 seconds

--------------------------------

python pipelineT2D.py -v --dir /home/nathan/school/research/multiInstanceLearning/cirrhosisTests --input cirrhosis.fasta --map cirrhosis.map --positive Encephalopathy --negative 'No Encephalopathy' --cluster uclust --svm misvm --result_dir results/option4-misvm-encVSno/ --output resultFile --split -1 --kmer 4 --write small_vectors

python gicf.py -v -i /home/nathan/school/research/multiInstanceLearning/cirrhosisTests/results/option4-misvm-encVSno/vectors

--------------------------------

K = 41 or K = 51 with read size limited to 100 seemed to work best. I chose K = 51.

--------------------------------

GeneMark: done, not sure how to use yet

Explicit association of clusters to labels with SVM-light
- take the prediction file and augment with explicit association with cluster labels and an example
- maybe augment with genemark results to predict genes that are most indicative of having or not having disease

Start writing my paper
- clarify direction of paper
- start with parts of introduction and related work sections from class paper, maybe some of methods (UCLUST, SVM-light, etc)
- remember matplotlib for charts: http://matplotlib.org/

Same data as MGWAS paper?
- can start downloading other patients with bulk downloader, but still not all data is available
- may have to ask paper authors where to find all data

--------------------------------

EXPERIMENTS for GICF (accuracy and F1 [maybe also runtime])

Number of iterations: 1, 3, 5, 10, 20
Mini-batch size: 0.01, 0.05, 0.1, 0.25, 1
(Not done) Selected from: Top 2%, Top 10%, Top 20%, Top 50%, All
Learning Rate: 0.00001, 0.00005, 0.0001, 0.0005, 0.001
Top-K: Yes or No
Kernel (Similarity): Yes or No
Part of Dataset: 1% or All

Since mini batches are randomized (as are weights), run each experiment 3-5 times to get range of results
Do training set as test set to see accuracy of that
Do both Cirrhosis and T2D datasets (must first assemble Cirrhosis data)

--------------------------------

  /* added code */
  int iter;
  double *wtemp = model->lin_weights;
  fprintf(predfl, "[");
  for(iter=0; iter < len; iter++){
    fprintf(predfl,"%lf", *wtemp);
    wtemp++;
    if(iter+1 < len)  fprintf(predfl,", ");
  }
  fprintf(predfl, "]\n");
  /* end added code */

1317: number of clusters from assembled fasta file

--------------------------------

k=4, out1
Best parameter settings [learn rate, lambda, mini batch size, descent iterations]: [0.0001, 60.0, 0.9, 10]
Average prediction: 0.762984045957
Best results: 
Accuracy: 0.633333333333
Precision and recall: 0.590909090909 and 0.866666666667
F1 Score: 0.702702702703
True Positive Rate and False Positive Rate: 0.866666666667 and 0.6


k=3, out1
Best parameter settings [rate, lambda, top_k, mini batch size, iterations]:
[0.0001, 60.0, 0.9, 0.01, 30]
Best results: 
Accuracy: 0.6
Precision and recall: 0.555555555556 and 1.0
F1 Score: 0.714285714286
True Positive Rate and False Positive Rate: 1.0 and 0.8


k=3, out1
Best parameter settings [rate, lambda, top_k, mini batch size, iterations]:
[5e-05, 60.0, 0.9, 0.01, 30]
Best results: 
Accuracy: 0.633333333333
Precision and recall: 0.583333333333 and 0.933333333333
F1 Score: 0.717948717949
True Positive Rate and False Positive Rate: 0.933333333333 and 0.666666666667


k=3, out1
Best parameter settings [rate, lambda, top_k, mini batch size, iterations]:
[0.0001, 60.0, 0.9, 0.01, 3]
Best results: 
Accuracy: 0.7
Precision and recall: 0.6875 and 0.733333333333
F1 Score: 0.709677419355
True Positive Rate and False Positive Rate: 0.733333333333 and 0.333333333333

k=3, out1
Best parameter settings [rate, lambda, top_k, mini batch size, iterations]:
[0.0001, 60.0, 0.9, 0.01, 30]
Best results: 
Accuracy: 0.566666666667
Precision and recall: 0.535714285714 and 1.0
F1 Score: 0.697674418605
True Positive Rate and False Positive Rate: 1.0 and 0.866666666667


--------------------------------


Pipeline (CAMIL) - Both H-BoW and D-BoW versions
MI-SVM: shows why Instance Space (IS) and Standard MIL assumption are bad (also do sbMIL?)
GICF: avoids standard MIL assumption and learns instance labels, but still IS
EMD+SVM?: Bag Space (BS) example, show why vocabulary needed in bioinformatics?
R packages from mgwas paper?: our way of comparing to original paper

Then: compare CAMIL to original paper results and explain why better (de novo, less training data)

Then: show CAMIL instance "labels" better than GICF (CAMIL should have some clusters labeled as clearly bad or good, whereas GICF labels not very differentiated)
Voting Framework (VF) from key instance detection paper?: like GICF but standard MI assumption




--------------------------------


TP:8
FP:0
TN:11
FN:4

Precision = TP / (TP + FP) = 8 / 8 = 1.0
Recall = TP / (TP + FN) = 8 / 12 = 0.667
F1 Score = 2 * 1 * 0.667 / (1 + 0.667) = 0.8002



--------------------------------


>>> a[-25:]
[0.009657, 0.009664, 0.009795, 0.009816, 0.009827, 0.009866, 0.009888, 0.00997, 0.009981, 0.009984, 0.010299, 0.010428, 0.010497, 0.010527, 0.010528, 0.010534, 0.010544, 0.010639, 0.010648, 0.010692, 0.010714, 0.010891, 0.011196, 0.011356, 0.012109]
>>> a[:25]
[-0.003668, -0.003551, -0.003546, -0.0031, -0.003083, -0.002915, -0.0029, -0.002899, -0.002852, -0.002782, -0.002708, -0.002693, -0.002603, -0.002581, -0.002536, -0.002519, -0.002502, -0.002492, -0.002476, -0.002439, -0.002431, -0.00241, -0.002391, -0.002371, -0.002366]



--------------------------------


#$ -q all-LoPri.q

D-BoW final performance (even split):
Accuracy on test set: 87.43% (160 correct, 23 incorrect, 183 total)
Precision/recall on test set: 83.84%/92.22%
F1 Score = 2*.8384*.9222 / (.8384+.9222) = 87.83%
Leave-one-out estimate of the error: error=16.30%
Leave-one-out estimate of the recall: recall=90.22%
Leave-one-out estimate of the precision: precision=79.81%
7 minutes and 59 seconds

H-BoW final performance (even split):
Accuracy on test set: 93.99% (172 correct, 11 incorrect, 183 total)
Precision/recall on test set: 98.77%/88.89%
F1 Score = 2*.9877*.8889 / (.9877+.8889) = 93.57%
Leave-one-out estimate of the error: error=11.96%
Leave-one-out estimate of the recall: recall=80.43%
Leave-one-out estimate of the precision: precision=94.87%
7 minutes and 21 seconds


D-BoW no feature engineering:
Accuracy on test set: 86.34% (158 correct, 25 incorrect, 183 total)
Precision/recall on test set: 80.95%/94.44%
F1 Score = 2*.8095*.9444 / (.8095+.9444) = 87.18%
Leave-one-out estimate of the error: error=17.93%
Leave-one-out estimate of the recall: recall=88.04%
Leave-one-out estimate of the precision: precision=78.64%
9 minutes and 13 seconds

H-BoW no feature engineering:
Accuracy on test set: 90.71% (166 correct, 17 incorrect, 183 total)
Precision/recall on test set: 98.67%/82.22%
F1 Score = 2*.9867*.8222 / (.9867+.8222) = 89.70%
Leave-one-out estimate of the error: error=10.87%
Leave-one-out estimate of the recall: recall=80.43%
Leave-one-out estimate of the precision: precision=97.37%
8 minutes, 49 seconds
