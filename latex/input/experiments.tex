%EXP

\subsection{Data, Software, and Hardware Used}

Our main dataset comes from a GWAS of Type 2 Diabetes (T2D) in Chinese adults, published by Qin et al \cite{qin041012}. The data is publicly available on the National Center for Biotechnology Information (NCBI) \cite{ncbi} website using the accession number SRP011011. The full dataset contains over 200 patients, but for our study we used a subset of 60 patients due to lengthy download and format conversion times. Of these 60 patients, 30 had T2D and 30 were controls. For the purpose of testing our cluster sampling methods, we also used a smaller dataset obtained from Dr. Patrick Gillevet of GMU, which is not publicly available. It contains 904 patients, 239 of whom have encephalopathy and 665 of whom are controls, but is much smaller because it uses 16S rRNA instead of whole genome data. The encephalopathy dataset contains about 1.3 million reads, while the T2D dataset contains about 1.3 billion reads.

As previously mentioned, we use the publicly-available UCLUST \cite{Edgar10} software for clustering. For classification, we use Support Vector Machines (SVMs) \cite{vap95}, one of the most powerful and versatile binary classifiers used 
in myriad applications. 
%
For a  binary classification problem, the SVM framework 
maximizes the separation between the two classes. In addition to the ubiquity and effectiveness of SVMs, they are well established in both supervised and multiple instance learning, making it easy to compare the two approaches. For our standard supervised SVM, we use svm-light \cite{joachims08}, a popular and publicly available implementation. For multiple instance learning, we use the python implementation by G. Doran and S. Ray ("MISVM") \cite{doran122013} for its ease of use and public availability.


\subsection{Efficient Unsupervised Clustering using UCLUST}
\label{uclustmethods}

From early experimental results, UCLUST can still be computationally infeasible for very large datasets such as the one we will be using, despite its generally excellent speed. For our T2D dataset, UCLUST was only able to cluster 2.8\% of the reads within 12 hours, at which point ARGO killed the batch job. UCLUST slows down as more clusters are formed, as each new read needs to be compared to more existing clusters. Thus, as the number of clusters grows, the execution time of UCLUST increases rapidly. The only way to feasibly complete the clustering phase in a reasonable amount of time was to cluster the patients individually in parallel, instead of clustering the reads of all patients together. However, this leads to the problem of having mismatched clusterings between patients, that is, cluster X from patient A may represent the same OTU as cluster Y from patient B. The solution is to compare the clusters from different patients and map them to each other, and then to combine clusters from different patients that represent the same OTU and output a single clustering output file for all patients. However, comparing every read from each cluster to every read from all other clusters is also computationally infeasible. Thus, we developed methods to sample representative reads from each patient and use them to create the consensus clustering. We explored a number of different methods, but two of them in particular were able to achieve significant speed improvements without significantly harming classification results. For each of them, we used a parameter "alpha", which was used to select 1 out of every alpha reads. For instance, if alpha=10, 1/10 of reads would be used. 

We refer to one of our methods as "seed re-clustering" (UCLUST refers to cluster centroids as "seeds"). In this method, the reads corresponding to the cluster seeds from each patient are copied into a temporary file, and then those reads are clustered. This runs quickly, since clusters in this setting tend to have hundreds to thousands of reads, so the number of cluster seeds is relatively small. We then construct a map, which maps each seed from its original cluster number to its new cluster number from the seed clustering. We go back to the individual patient clustering output, and select 1 out of every alpha lines to be placed in the consensus clustering file. As we write the lines to the consensus file, we use the map we developed to change the cluster number for the line from the original clustering number to the new consensus cluster number. We refer to the other method as "two round clustering". We select one out of every alpha reads from the clustering output of each patient, place them in a single file, and run UCLUST on this smaller subset to arrive at a consensus clustering. The main difference between two round clustering and seed re-clustering is that here we select a distribution of reads from the original clustering to determine the consensus clustering, instead of cluster seeds/centroids.

We sought to empirically evaluate how these methods affected clustering runtime and classification accuracy, since feature vectors are generated from the clustering output and thus classification results are affected by the clustering methods. Without use of these sampling methods, UCLUST didn't finish within ARGO's 12 hour time limit on the T2D dataset, so we couldn't evaluate the classification results on that dataset and compare them to the classification results with the clustering sample methods. In order to evaluate these methods, we used the aforementioned Encephalopathy dataset, which is much smaller. We measured the time it took to perform UCLUST on all patients at once, as well as the time taken by each of our two sampling methods. We then used the respective clustering outputs to generate feature vectors and run svm-light classification (as described in the next section) and compared the results, which are discussed in the "Experimental Results" section. For UCLUST, default settings were used, except the threshold for placing two sequences in the same cluster was set to 40\% match (--id 0.40), and the --usersort option was used.


\subsection{Supervised and Multiple Instance Classification using Support Vector Machines (SVMs)}
\label{svm}

For our formulation we use SVMs to make clinical phenotype prediction for each patient sample based on their  input metagenome sequence samples represented with their clustering or taxa membership features. With our clustering approach,  we have a set of reads that have been assigned to clusters based on UCLUST and our techniques. We now generate feature vectors from each patient from this clustering output. We follow a different process of feature vector generation for svm-light and MISVM. For each method, we read through the consensus clustering output from UCLUST line-by-line, forming feature vectors as we go. UCLUST output lines provide the cluster number, the percentage match to the cluster seed, and the patient that read comes from.

For svm-light, we have one feature vector per patient. We use each cluster/OTU as a feature, meaning that the presence of various microbes are the features for the patient. Each number (feature) in the vector corresponds to a cluster/OTU, and the value for that number corresponds to how closely the read from the patient matched the cluster seed. For each input 
sequence, we use the percentage match to its cluster seed as 
the value for that feature and average the 
sequence match if multiple reads from the metagenome samples 
are assigned to the same cluster by UCLUST. Each sequence read includes a label for the patient that it came from, so each read only affects the feature vector corresponding to the patient that it came from. For example, say patient A has a read with 95\% match to OTU 2, a read that is the cluster seed of OTU 3, a read that is a 93\% match to OTU 2, a read that is a 97\% match to OTU 5, and no reads for OTU 1 or 4. Patient A's feature vector would then look like: [0 0.94 1 0 0.97]. We first initialize the patient feature vectors to all 0s and then iterate through the UCLUST output lines and update the feature vectors as we go. For MISVM, patients are bags, reads for patients are instances, and each read/instance has a feature vector. We iterate through the UCLUST output. For each read, we add that read as an instance to the relevant patient bag. The feature vector for that read contains one number: the cluster number that the read belongs to.  We compared the runtime and accuracy of the two implementations, which both used a linear kernel. In both cases, the training and test set each contained 30 patients, and each contained 15 patients with type 2 diabetes and 15 control (healthy) patients. The results are discussed in the "Experimental Results" section.
